{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of chars: 82\n"
     ]
    }
   ],
   "source": [
    "files= ['austen-emma.txt',\n",
    " 'austen-persuasion.txt',\n",
    " 'austen-sense.txt',\n",
    " 'bible-kjv.txt',\n",
    " 'blake-poems.txt']\n",
    "raw = gutenberg.raw(files)\n",
    "\n",
    "\n",
    "listOfchars = sorted(list(set(raw)))\n",
    "print('total number of chars:', len(listOfchars))\n",
    "character_to_Index = dict((c, i) for i, c in enumerate(listOfchars))\n",
    "Index_to_character = dict((i, c) for i, c in enumerate(listOfchars))\n",
    "\n",
    "max_length_of_seq = 50+1\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(listOfchars) - max_length_of_seq):\n",
    "    sentences.append(listOfchars[i: i + max_length_of_seq])\n",
    "    next_chars.append(listOfchars[i + max_length_of_seq])\n",
    "\n",
    "x = np.zeros((len(sentences), max_length_of_seq, len(listOfchars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(listOfchars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, character_to_Index[char]] = 1\n",
    "    y[i, character_to_Index[next_chars[i]]] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(max_length_of_seq, len(listOfchars))))\n",
    "model.add(Dense(len(listOfchars)))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"modelc.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"modelc.h5\")\n",
    "\n",
    "\n",
    "model.fit(x, y, batch_size=128, epochs=100,callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
