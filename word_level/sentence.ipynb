{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her and he said unto him i will not be\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "\n",
    "def load_doc(filename):\n",
    "        \n",
    "        file = open(filename, 'r')\n",
    "        \n",
    "        text = file.read()\n",
    "        \n",
    "        file.close()\n",
    "        return text\n",
    " \n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "        result = list()\n",
    "        in_text = seed_text\n",
    "        \n",
    "        for _ in range(n_words):\n",
    "            \n",
    "            encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "            \n",
    "            encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "            \n",
    "            yhat = model.predict_classes(encoded, verbose=0)\n",
    "            \n",
    "            out_word = ''\n",
    "            for word, index in tokenizer.word_index.items():\n",
    "                if index == yhat:\n",
    "                    out_word = word\n",
    "                    break\n",
    "            \n",
    "            in_text += ' ' + out_word\n",
    "            result.append(out_word)\n",
    "        return ' '.join(result)\n",
    " \n",
    "#load cleaned text sequences\n",
    "in_filename = 'train_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1\n",
    " \n",
    "\n",
    "model = load_model('Lstm_model.h5')\n",
    " \n",
    "\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    " \n",
    "\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "\n",
    "\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 10)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for the lord is the lord of hosts and\n"
     ]
    }
   ],
   "source": [
    "seed_text = lines[randint(0,len(lines))]\n",
    "#print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 10)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with the altar of the lord and the lord shall\n"
     ]
    }
   ],
   "source": [
    "seed_text = lines[randint(0,len(lines))]\n",
    "#print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 10)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first and consulteth whether he be able with ten thousand to meet him that cometh against him with twenty thousand and isaac intreated the lord for his wife because she was barren and the lord was intreated of him and rebekah his wife conceived he will take the tenth of your\n",
      "\n",
      "fathers and the lord shall be the son of israel\n"
     ]
    }
   ],
   "source": [
    "seed_text = lines[randint(0,len(lines))]\n",
    "#print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 10)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and said unto him go not to the lord and\n"
     ]
    }
   ],
   "source": [
    "seed_text = lines[randint(0,len(lines))]\n",
    "#print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 10)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the king of babylon came to the house of\n"
     ]
    }
   ],
   "source": [
    "seed_text = lines[randint(0,len(lines))]\n",
    "#print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 10)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
